{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "import glob\n",
    "import calendar\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import xesmf as xe\n",
    "import scipy.stats\n",
    "import os.path\n",
    "import netCDF4\n",
    "# from netCDF4 import Dataset#, num2date\n",
    "# import dask\n",
    "from datetime import datetime\n",
    "#np.seterr(divide='ignore', invalid='ignore')\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to all models\n",
    "path_ecearth = '/esarchive/exp/CMIP6/dcppA-hindcast/ec-earth3/cmip6-dcppA-hindcast_i1p1/DCPP/EC-Earth-Consortium/EC-Earth3/dcppA-hindcast/r2i1p1f1/SImon/siconc/gn/v20200101/'\n",
    "path_canesm5 = '/esarchive/exp/CMIP6/dcppA-hindcast/canesm5/cmip6-dcppA-hindcast_i1p2/DCPP/CCCma/CanESM5/dcppA-hindcast/r2i1p2f1/SImon/siconc/gn/v20200101/'\n",
    "path_norcpm1_1 = '/esarchive/exp/CMIP6/dcppA-hindcast/norcpm1/cmip6-dcppA-hindcast_i1p1/DCPP/NCC/NorCPM1/dcppA-hindcast/r2i1p1f1/SImon/siconc/gn/v20200101/'\n",
    "path_norcpm1_2 = '/esarchive/exp/CMIP6/dcppA-hindcast/norcpm1/cmip6-dcppA-hindcast_i2p1/DCPP/NCC/NorCPM1/dcppA-hindcast/r2i2p1f1/SImon/siconc/gn/v20200101/'\n",
    "path_ipsl = '/esarchive/exp/CMIP6/dcppA-hindcast/ipsl-cm6a-lr/cmip6-dcppA-hindcast_i1p1/DCPP/IPSL/IPSL-CM6A-LR/dcppA-hindcast/r2i1p1f1/SImon/siconc/gn/v20200101/'\n",
    "path_miroc = '/esarchive/exp/CMIP6/dcppA-hindcast/miroc6/cmip6-dcppA-hindcast_i1p1/DCPP/MIROC/MIROC6/dcppA-hindcast/r2i1p1f1/SImon/siconc/gn/v20200101/'\n",
    "path_mpi = '/esarchive/exp/CMIP6/dcppA-hindcast/mpi-esm1-2-hr/cmip6-dcppA-hindcast_i1p1/DCPP/MPI-M/MPI-ESM1-2-HR/dcppA-hindcast/r2i1p1f1/SImon/siconc/gn/v20200101/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET OPTIONS #\n",
    "\n",
    "# Dictionary with model names and consortiums for paths\n",
    "model_dic = {'ecearth': ['ec-earth3', 'i2p1', 'EC-Earth-Consortium/EC-Earth3', 'EC-Earth3'], 'norcpm1_1': ['norcpm1', 'i1p1', 'NCC/NorCPM1'],\n",
    "             'norcpm1_2': ['norcpm1', 'i2p1', 'NCC/NorCPM1'], 'canesm': ['canesm5', 'i1p2', 'CCCma/CanESM5'],\n",
    "             'ipsl_cm': ['ipsl-cm6a-lr', 'i1p1', 'IPSL/IPSL-CM6A-LR'], 'miroc': ['miroc6', 'i1p1', 'MIROC/MIROC6'],\n",
    "             'mpi': ['mpi-esm1-2-hr', 'i1p1', 'MPI-M/MPI-ESM1-2-HR']}\n",
    "\n",
    "path1 = '/esarchive/exp/CMIP6/dcppA-hindcast/'\n",
    "path2 = 'cmip6-dcppA-hindcast_' \n",
    "path3 = 'dcppA-hindcast'\n",
    "compo = 'SImon'\n",
    "mod_compo = 'seaIce'\n",
    "vdate = 'v20200101/'\n",
    "var = 'siconc'\n",
    "pathout = '/esarchive/scratch/ruben/dcpp/data/'\n",
    "pathout_plot = '/esarchive/scratch/ruben/dcpp/plots/'\n",
    "\n",
    "# Members EC-Earth\n",
    "mem_pred1_ecearth = 6\n",
    "mem_pred2_ecearth = 10\n",
    "members_pred_ecearth = []\n",
    "for r in range(mem_pred1_ecearth, mem_pred2_ecearth+1):\n",
    "    me_pred_ecearth = 'r{0}i2p1f1'.format(r)\n",
    "    members_pred_ecearth.append(me_pred_ecearth)\n",
    "\n",
    "year1 = 1970 #61\n",
    "year2 = 2010 #00\n",
    "# Chunks EC-Earth\n",
    "chunks_pred_ecearth = []\n",
    "for j in range(year1, year2+1):\n",
    "    chupred = '{0}01-{1}12'.format(str(j), str(j))\n",
    "    chunks_pred_ecearth.append(chupred)\n",
    "    \n",
    "print(chunks_pred_ecearth)\n",
    "\n",
    "# Chunks HadiSST\n",
    "chunks_hadisst = []\n",
    "for j in range(year1, year2+1):\n",
    "    for t in range(1, 13):\n",
    "        chu_disst = '{0}{1}'.format(str(j), str(t).zfill(2))\n",
    "        chunks_hadisst.append(chu_disst)\n",
    "\n",
    "#print(chunks_hadisst)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HadISST # (Continous Timeseries)\n",
    "hadisst_path = '/esarchive/obs/ukmo/hadisst_v2.2/monthly_mean/sic/'\n",
    "\n",
    "filenames_hadisst = []\n",
    "for chu in chunks_hadisst:\n",
    "    filename_ = glob.glob(hadisst_path + 'sic_' + chu + '.nc')\n",
    "    filenames_hadisst.append(filename_[0])\n",
    "    \n",
    "list_hadisst = []\n",
    "for file_ in filenames_hadisst:\n",
    "    date_hadisst = file_.split('sic_')[1].split('.')[0]\n",
    "    \n",
    "    ds = xr.open_dataset(file_, decode_times=False)\n",
    "    mon_index = xr.cftime_range(date_hadisst, periods=1, freq='MS')\n",
    "    ds.coords['time'] = mon_index\n",
    "    list_hadisst.append(ds)\n",
    "    \n",
    "ds_hadisst = xr.concat(list_hadisst, dim='time')\n",
    "ds_hadisst = ds_hadisst.sortby('time') # 124 Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histo2Hindcast #\n",
    "ds_hadisst2 = ds_hadisst['sic']*100 #.to_array()\n",
    "\n",
    "formatted_hadisst = []\n",
    "for s_dates in range(0, len(chunks_pred_ecearth)):\n",
    "    forecast_period = chunks_pred_ecearth[s_dates]\n",
    "    first_step = forecast_period.split('-')[0]\n",
    "    last_step = forecast_period.split('-')[1]\n",
    "    start_slice = '-'.join([first_step[:4], first_step[-2:]])\n",
    "    end_slice = '-'.join([last_step[:4], last_step[-2:]])\n",
    "    sele = ds_hadisst2.sel(time=slice(start_slice, end_slice))\n",
    "    sele['time'] = np.arange(1, 13) # ftime\n",
    "    formatted_hadisst.append(sele)\n",
    "    \n",
    "sdates_dim_hadisst = xr.DataArray(chunks_pred_ecearth, name='sdate', dims='sdate')\n",
    "reshaped_hadisst = xr.concat(formatted_hadisst, dim=sdates_dim_hadisst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load EC-Earth (the only with chunks of 1 year, all the rest 10 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EC-Earth # 1st year\n",
    "\n",
    "path_saving_ecearth = '{0}{1}_pred_ecearth_mean_{2}-{3}_ensemble_year1.nc'.format(pathout, var, str(year1), str(year2))\n",
    "\n",
    "if os.path.isfile(path_saving_ecearth):\n",
    "    print('File exists. Loading... ') # 40x12x292x362\n",
    "    ecearth_ensemble = xr.open_dataarray(path_saving_ecearth, decode_times=False)\n",
    "else:\n",
    "    print('IT DOES NOT EXIST') # Load everything\n",
    "    HIND_ecearth = []\n",
    "    for mem in members_pred_ecearth:\n",
    "        filenames_pred = []\n",
    "        for chu in chunks_pred_ecearth:\n",
    "\n",
    "            start_date = int(chu.split('01-')[0]) - 1\n",
    "\n",
    "            file_path_pred = '{0}{1}/{2}{3}{4}{5}/{6}/{7}/{8}/{9}/gn/{10}'.format(path1, model_dic['ecearth'][0], path2,                     \n",
    "                                                                                model_dic['ecearth'][1], '/DCPP/',\n",
    "                                                                                model_dic['ecearth'][2], path3, mem, compo, \n",
    "                                                                                var, vdate)\n",
    "\n",
    "            filename_ = glob.glob(file_path_pred + var + '_' + compo + '_' + model_dic['ecearth'][3] + '_' + path3 + '_s' +\n",
    "                                  str(start_date) + '-' + mem + '_gn_' + chu + '.nc')        \n",
    "\n",
    "            filenames_pred.append(filename_[0])\n",
    "\n",
    "        f_list_pred = sorted(filenames_pred)\n",
    "\n",
    "        list_pred = []\n",
    "        for file_ in f_list_pred:\n",
    "            ds = xr.open_dataset(file_, decode_times=False, chunks={'time': 1})\n",
    "            ds['time'] = np.arange(1, 13) # forecast time 1st year\n",
    "            list_pred.append(ds)\n",
    "\n",
    "        da_num_pred = xr.DataArray(chunks_pred_ecearth, name='sdate', dims='sdate')\n",
    "        ds_pred_num = xr.concat(list_pred, dim=da_num_pred)\n",
    "\n",
    "        HIND_ecearth.append(ds_pred_num)\n",
    "\n",
    "    hindcast = xr.DataArray(members_pred_ecearth, name='member', dims='member')\n",
    "    ds_hind = xr.concat(HIND_ecearth, dim=hindcast)\n",
    "    # Ensemble Mean and Start Date Mean\n",
    "    ecearth_ensemble = ds_hind[var].mean(dim='member')\n",
    "    del ds_hind\n",
    "\n",
    "    # print('Size of the file: ', pred_clim.nbytes/1e6, 'Mb')\n",
    "    \n",
    "    ecearth_ensemble.to_netcdf(path = path_saving_ecearth, format = 'NETCDF4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Rest of Models (chunks of 10 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dic_10y = {'canesm': ['canesm5', 'i1p2', 'CCCma/CanESM5', 2, 2, 'CanESM5', 121], # 1 (member1), 1 (member2)\n",
    "                 'norcpm1_1': ['norcpm1', 'i1p1', 'NCC/NorCPM1', 1, 1, 'NorCPM1', 124],\n",
    "                 'norcpm1_2': ['norcpm1', 'i2p1', 'NCC/NorCPM1', 1, 1, 'NorCPM1', 124],\n",
    "                 'ipsl_cm': ['ipsl-cm6a-lr', 'i1p1', 'IPSL/IPSL-CM6A-LR', 1, 1, 'IPSL-CM6A-LR', 121],\n",
    "                 'miroc': ['miroc6', 'i1p1', 'MIROC/MIROC6', 1, 1, 'MIROC6', 123]\n",
    "                }\n",
    "\n",
    "             #'mpi': ['mpi-esm1-2-hr', 'i1p1', 'MPI-M/MPI-ESM1-2-HR']}\n",
    "\n",
    "mod_to_load = ['miroc']\n",
    "                \n",
    "year1=1970\n",
    "year2=2010\n",
    "\n",
    "for mod in mod_to_load:\n",
    "\n",
    "    # Members\n",
    "    members_pred_mod = []\n",
    "    for r in range(model_dic_10y[mod][3],model_dic_10y[mod][4]+1):\n",
    "        me_pred_mod = 'r{0}{1}f1'.format(r, model_dic_10y[mod][1])\n",
    "        members_pred_mod.append(me_pred_mod)\n",
    "\n",
    "    # Chunks \n",
    "    chunks_pred_mod = []\n",
    "    for j in range(year1, year2+1):\n",
    "        if mod == 'canesm' or mod == 'ipsl_cm':\n",
    "            chupred = '{0}01-{1}12'.format(str(j), str(j+9))\n",
    "            chunks_pred_mod.append(chupred)\n",
    "        elif mod == 'norcpm1_1' or mod == 'norcpm1_2':\n",
    "            chupred = '{0}10-{1}12'.format(str(j-1), str(j+9))\n",
    "            chunks_pred_mod.append(chupred)\n",
    "        elif mod == 'miroc':\n",
    "            chupred = '{0}11-{1}12'.format(str(j-1), str(j+9))\n",
    "            chunks_pred_mod.append(chupred)\n",
    "            \n",
    "#   HIND_mod = []\n",
    "    for mem in members_pred_mod:\n",
    "\n",
    "        path_saving_mod10 = '{0}{1}_pred_{2}_{3}_{4}-{5}_10y.nc'.format(pathout, var, mod, mem, str(year1), str(year2))\n",
    "\n",
    "        if os.path.isfile(path_saving_mod10):\n",
    "            print('File exists. Loading... ')\n",
    "            mod = xr.open_dataset(path_saving_mod10, decode_times=False)[var]\n",
    "        else:\n",
    "            print('IT DOES NOT EXIST') # Load everything\n",
    "\n",
    "            HIND_mod = []\n",
    "            filenames_pred = []\n",
    "            for chu in chunks_pred_mod:\n",
    "                if mod == 'canesm' or mod == 'ipsl_cm':\n",
    "                    start_date = int(chu.split('01-')[0]) - 1\n",
    "                elif mod == 'norcpm1_1' or mod == 'norcpm1_2':\n",
    "                    start_date = int(chu.split('10-')[0])\n",
    "                elif mod == 'miroc':\n",
    "                    start_date = int(chu.split('11-')[0])\n",
    "                    \n",
    "\n",
    "                file_path_pred = '{0}{1}/{2}{3}{4}{5}/{6}/{7}/{8}/{9}/gn/{10}'.format(path1, model_dic_10y[mod][0], path2, model_dic_10y[mod][1], '/DCPP/', model_dic_10y[mod][2], path3, mem, compo, var, vdate)\n",
    "\n",
    "                filename_ = glob.glob(file_path_pred + var + '_' + compo + '_' + str(model_dic_10y[mod][5]) + '_' + path3 + '_s' + str(start_date) + '-' + mem + '_gn_' + chu + '.nc')\n",
    "\n",
    "                filenames_pred.append(filename_[0])\n",
    "\n",
    "            f_list_pred = sorted(filenames_pred)\n",
    "            list_pred = []\n",
    "            for file_ in f_list_pred:\n",
    "                ds = xr.open_dataset(file_, decode_times=False, chunks={'time': 1})\n",
    "                ds['time'] = np.arange(1, model_dic_10y[mod][6]) # forecast time 1st year\n",
    "                list_pred.append(ds)\n",
    "\n",
    "            da_num_pred = xr.DataArray(chunks_pred_mod, name='sdate', dims='sdate')\n",
    "            ds_pred_num = xr.concat(list_pred, dim=da_num_pred)\n",
    "\n",
    "            HIND_mod.append(ds_pred_num)\n",
    "\n",
    "            ds_mod = xr.concat(HIND_mod, dim='time')\n",
    "            ds_mod.to_netcdf(path_saving_mod10, format = 'NETCDF4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select 1st year from 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the 10y models (CanESM)\n",
    "if mod == 'canesm' or mod == 'ipsl_cm':\n",
    "    sele_mod = mod[:,0:12,:,:]\n",
    "elif mod == 'norcpm1_1' or mod == 'norcpm1_2':\n",
    "    sele_mod = mod[:,3:15,:,:] # Los chunks empiezan en octubre\n",
    "elif mod == 'miroc':\n",
    "    sele_mod = mod[:,2:15,:,:]\n",
    "\n",
    "# LACKING MPI\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly Calculation #\n",
    "#######################\n",
    "# ~ HadiSST\n",
    "sd_mean_hadisst = reshaped_hadisst.groupby('time').mean(dim='sdate') # , skipna=True, keep_attrs = True)\n",
    "ano_hadisst = reshaped_hadisst.groupby('time') - sd_mean_hadisst\n",
    "\n",
    "# ~ EC-Earth\n",
    "sd_mean_ecearth = ecearth_ensemble.groupby('time').mean(dim='sdate', keep_attrs = True)\n",
    "ano_ecearth = ecearth_ensemble.groupby('time') - sd_mean_ecearth\n",
    "\n",
    "# ~ CanESM\n",
    "sd_mean_mod = sele_mod.groupby('time').mean(dim='sdate', keep_attrs = True)\n",
    "ano_mod = sele_mod.groupby('time') - sd_mean_mod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate Model Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to interpolate #\n",
    "dic_interp = {'canesm': ano_mod} #'ecearth': ano_ecearth, 'norcpm1_1': 'NorCPM1_1'}\n",
    "mod_to_interp = ['canesm'] #['ecearth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate Model Anomalies to regular # ~~~~~~\n",
    "nr_dates = year2 - year1 + 1\n",
    "\n",
    "dict_out = {}\n",
    "\n",
    "for mod in mod_to_interp:\n",
    "\n",
    "    latitude = dic_interp[mod].latitude\n",
    "    longitude = dic_interp[mod].longitude\n",
    "\n",
    "    res_new = 1 # degrees; the resolution of the new grid\n",
    "    lat_new = -90 + np.arange((2*90)/res_new) \n",
    "\n",
    "    lat_new = lat_new*-1  # reverse latitudes \n",
    "\n",
    "    lon_new = np.arange((360)/res_new) \n",
    "    lon_new, lat_new = np.meshgrid(lon_new,lat_new)\n",
    "\n",
    "    data_new = np.empty(shape=(nr_dates,12,180,360))\n",
    "\n",
    "    \n",
    "    for sdate in range(0, nr_dates):\n",
    "        for mon in range(0, 12):\n",
    "\n",
    "            data = np.squeeze(np.array(ano_mod[sdate,mon,:,:])) # \n",
    "            ndim0 = np.size(data,axis=0)\n",
    "            ndim1 = np.size(data,axis=1)\n",
    "\n",
    "            # Regrid\n",
    "          #  data_new = data\n",
    "            lat_temp = latitude.copy()\n",
    "            lon_temp = longitude.copy()\n",
    "            method = np.str('nearest_s2d')\n",
    "\n",
    "            # Make sure the dimensions of the new grid are in the right order\n",
    "            lat_temp = lat_new.copy()\n",
    "            lon_temp = lon_new.copy()\n",
    "            if ndim0>ndim1:\n",
    "                lat_temp = np.transpose(lat_temp)\n",
    "                lon_temp = np.transpose(lon_temp)\n",
    "\n",
    "            lat_temp2 = latitude.copy()\n",
    "            lon_temp2 = longitude.copy()\n",
    "\n",
    "            # Create the xarray datasets to feed into the xesmf regridder\n",
    "            ds_in = xr.Dataset({'lat': (['x','y'],lat_temp2),\n",
    "                                'lon': (['x','y'],lon_temp2)})\n",
    "            ds_out = xr.Dataset({'lat': (['x','y'],lat_temp),\n",
    "                                    'lon': (['x','y'],lon_temp)})\n",
    "            # Regrid the data\n",
    "            f = xe.Regridder(ds_in, ds_out, method, periodic=True, reuse_weights=True)\n",
    "            data_new[sdate,mon,:,:] = f(data)\n",
    "            \n",
    "    dict_out['{0}'.format(mod)] = data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ACC (Models & Reference) #\n",
    "\n",
    "ano_had = np.nan_to_num(ano_hadisst)\n",
    "#np.isnan(ano_had).any()\n",
    "\n",
    "mod_to_corr = ['canesm'] #['ecearth']\n",
    "dict_corr = {}\n",
    "for mod in mod_to_corr:\n",
    "    \n",
    "    ano_mod = np.nan_to_num(dict_out[mod])\n",
    "    \n",
    "    corr_coef = np.empty(shape=(12, 180, 360))\n",
    "    pvalue = np.empty(shape=(12, 180, 360))\n",
    "    for mon in range(0,12):\n",
    "        for lat in range(0,50): # Only correlations for the Arctic\n",
    "            for lon in range(0,360):\n",
    "                corr = scipy.stats.pearsonr(np.squeeze(ano_mod[:,mon,lat,lon]), np.squeeze(ano_had[:,mon,lat,lon])) \n",
    "                \n",
    "                corr_coef[mon,lat,lon] = corr[1]\n",
    "                pvalue[mon,lat,lon] = corr[0]\n",
    "    # Only significant values will be kept with 1\n",
    "    pvalue[pvalue>=0.05] = np.nan\n",
    "    pvalue[pvalue<0.05] = 1\n",
    "    dict_corr['{0}'.format(mod)] = (corr_coef, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = 'canesm'\n",
    "path_saving_acc = '{0}{1}_pred_{2}_{3}_{4}-{5}_ACC_y1.nc'.format(pathout, var, mod, mem, str(year1), str(year2))\n",
    "path_saving_pval = '{0}{1}_pred_{2}_{3}_{4}-{5}_pvalue_y1.nc'.format(pathout, var, mod, mem, str(year1), str(year2))\n",
    "\n",
    "array_acc = xr.DataArray(dict_corr[mod][0])\n",
    "array_acc.to_netcdf(path_saving_acc, format = 'NETCDF4')\n",
    "\n",
    "array_pval = xr.DataArray(dict_corr[mod][1])\n",
    "array_pval.to_netcdf(path_saving_pval, format = 'NETCDF4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACC Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "month_to_plot = [9] # 3 March / 9 September\n",
    "for mes in month_to_plot:\n",
    "    fig1, axes = plt.subplots(figsize=(6,6), constrained_layout=False) # 20,20\n",
    "    index = 0\n",
    "    for m in mod_to_plot:\n",
    "        index += 1\n",
    "        axes.set_axis_off()\n",
    "\n",
    "        corr_model = array_acc[mes,:,:]\n",
    "\n",
    "        # New evenly spaced, monotonically increasing lat-lon grid for regridding the sea ice\n",
    "        # concentration for the contour plot (otherwise the contour will reverse on itself)\n",
    "        res_new = 1 # degrees; the resolution of the new grid\n",
    "        lat_new = -90 + np.arange((2*90)/res_new) # 1+(2*90)\n",
    "\n",
    "        lon_new = np.arange((360)/res_new) # 1 +(360\n",
    "        lon_new, lat_new = np.meshgrid(lon_new,lat_new)\n",
    "\n",
    "        ice_edge_conc = 15 # Sea Ice Edge # I would have to plot with clim SIC !!\n",
    "\n",
    "        # Compute a circle in axes coordinates, which we can use as a boundary\n",
    "        # for the map. We can pan/zoom as much as we like - the boundary will be\n",
    "        # permanently circular.\n",
    "        theta = np.linspace(0, 2*np.pi, 100)\n",
    "        center, radius = [0.5, 0.5], 0.5\n",
    "        verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "        circle = mpath.Path(verts * radius + center)\n",
    "        # Make a pcolor plot of sea ice concentration, and contour the sea ice edge\n",
    "        ax = fig1.add_subplot(1, 1, index, projection = ccrs.NorthPolarStereo()) # 5, 4\n",
    "        ax.add_feature(cfeature.LAND,zorder=100,edgecolor='black',facecolor='Grey')\n",
    "        ax.set_boundary(circle, transform=ax.transAxes)\n",
    "        ax.set_extent([-180, 180, 55, 90], crs=ccrs.PlateCarree())\n",
    "        this = ax.pcolormesh(lon_temp,lat_temp, corr_model, transform=ccrs.PlateCarree(),\n",
    "                             cmap = plt.cm.RdYlBu_r, vmin=-1, vmax=1)\n",
    "        # this2 = ax.contour(lon_temp,lat_temp,mydata_new,15,transform=ccrs.PlateCarree(),colors='green')\n",
    "        cf = ax.scatter(lon_temp, lat_temp, s=array_pval[mes,:,], color='#000000', marker='^', transform=ccrs.PlateCarree())\n",
    "#         plt.title('ACC %s' % (dict_title[m]))\n",
    "    \n",
    "    fig1.colorbar(this, ax=axes, orientation='horizontal', fraction = 0.09, label = 'ACC')#, shrink=-0.6)\n",
    "#     plt.show()\n",
    "    plt.savefig('{0}ACC_{1}_canesm.eps'.format(pathout_plot, str(mes)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP of ACC:\n",
    "#~~~~~~~~~~~~~#\n",
    "\n",
    "dict_title = {'ecearth': 'EC-Earth', 'canesm': 'CanESM'  ,'norcpm1_1': 'NorCPM1_1'}\n",
    "mod_to_plot = ['canesm'] #['ecearth']\n",
    "\n",
    "month_to_plot = [9] # 3 March / 9 September\n",
    "for mes in month_to_plot:\n",
    "    fig1, axes = plt.subplots(figsize=(6,6), constrained_layout=False) # 20,20\n",
    "    index = 0\n",
    "    for m in mod_to_plot:\n",
    "        index += 1\n",
    "        axes.set_axis_off()\n",
    "\n",
    "        corr_model = dict_corr[m][0][mes,:,:]\n",
    "\n",
    "        # New evenly spaced, monotonically increasing lat-lon grid for regridding the sea ice\n",
    "        # concentration for the contour plot (otherwise the contour will reverse on itself)\n",
    "        res_new = 1 # degrees; the resolution of the new grid\n",
    "        lat_new = -90 + np.arange((2*90)/res_new) # 1+(2*90)\n",
    "\n",
    "        lon_new = np.arange((360)/res_new) # 1 +(360\n",
    "        lon_new, lat_new = np.meshgrid(lon_new,lat_new)\n",
    "\n",
    "        ice_edge_conc = 15 # Sea Ice Edge # I would have to plot with clim SIC !!\n",
    "\n",
    "        # Compute a circle in axes coordinates, which we can use as a boundary\n",
    "        # for the map. We can pan/zoom as much as we like - the boundary will be\n",
    "        # permanently circular.\n",
    "        theta = np.linspace(0, 2*np.pi, 100)\n",
    "        center, radius = [0.5, 0.5], 0.5\n",
    "        verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "        circle = mpath.Path(verts * radius + center)\n",
    "        # Make a pcolor plot of sea ice concentration, and contour the sea ice edge\n",
    "        ax = fig1.add_subplot(1, 1, index, projection = ccrs.NorthPolarStereo()) # 5, 4\n",
    "        ax.add_feature(cfeature.LAND,zorder=100,edgecolor='black',facecolor='Grey')\n",
    "        ax.set_boundary(circle, transform=ax.transAxes)\n",
    "        ax.set_extent([-180, 180, 55, 90], crs=ccrs.PlateCarree())\n",
    "        this = ax.pcolormesh(lon_temp,lat_temp, corr_model, transform=ccrs.PlateCarree(),\n",
    "                             cmap = plt.cm.RdYlBu_r, vmin=-1, vmax=1)\n",
    "        # this2 = ax.contour(lon_temp,lat_temp,mydata_new,15,transform=ccrs.PlateCarree(),colors='green')\n",
    "        cf = ax.scatter(lon_temp, lat_temp, s=dict_corr[m][1][mes,:,], color='#000000', marker='^', transform=ccrs.PlateCarree())\n",
    "        plt.title('ACC %s' % (dict_title[m]))\n",
    "    \n",
    "    fig1.colorbar(this, ax=axes, orientation='horizontal', fraction = 0.09, label = 'ACC')#, shrink=-0.6)\n",
    "#     plt.show()\n",
    "    plt.savefig('{0}ACC_{1}_canesm.eps'.format(pathout_plot, str(mes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open DataSets (Specific time steps for visualizing SIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC-EARTH #\n",
    "sic_ecearth = xr.open_dataset(path_ecearth + 'siconc_SImon_EC-Earth3_dcppA-hindcast_s1962-r2i1p1f1_gn_196211-196310.nc')\n",
    "print('Size of the file: ', sic_ecearth.nbytes/1e6, 'Mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORCPM1_1 #\n",
    "sic_norcpm1_1 = xr.open_dataset(path_norcpm1_1 + 'siconc_SImon_NorCPM1_dcppA-hindcast_s1962-r2i1p1f1_gn_196210-197212.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORCPM1_2 #\n",
    "sic_norcpm1_2 = xr.open_dataset(path_norcpm1_2 + 'siconc_SImon_NorCPM1_dcppA-hindcast_s1962-r2i2p1f1_gn_196210-197212.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CanESM5 #\n",
    "sic_canesm5 = xr.open_dataset(path_canesm5 + 'siconc_SImon_CanESM5_dcppA-hindcast_s1961-r2i1p2f1_gn_196201-197112.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPSL-CM6 #\n",
    "sic_ipsl = xr.open_dataset(path_ipsl + 'siconc_SImon_IPSL-CM6A-LR_dcppA-hindcast_s1961-r2i1p1f1_gn_196201-197112.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIROC6 # \n",
    "sic_miroc = xr.open_dataset(path_miroc + 'siconc_SImon_MIROC6_dcppA-hindcast_s1962-r2i1p1f1_gn_196211-197212.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPI-ESM1 #\n",
    "sic_mpi = xr.open_dataset(path_mpi + 'siconc_SImon_MPI-ESM1-2-HR_dcppA-hindcast_s1962-r2i1p1f1_gn_196211-197212.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSIDC 0051 monthly data #\n",
    "dfile = '/esarchive/obs/nasa/nsidc0051_gsfc_nasateam_seaice/processed/north/monthly_mean/siconc_r1i1p1_mon_197901_nh-psn25.nc'\n",
    "sic_nsidc = xr.open_dataset(dfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HADISST #\n",
    "hadisst_path = '/esarchive/obs/ukmo/hadisst_v2.2/monthly_mean/sic/'\n",
    "sic_hadisst = xr.open_dataset(hadisst_path + 'sic_196101.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT DATA TO BE PLOTTED\n",
    "dic_mod = {'ecearth': sic_ecearth, 'norcpm1_1': sic_norcpm1_1,\n",
    "             'norcpm1_2': sic_norcpm1_2, 'canesm': sic_canesm5,\n",
    "             'ipsl_cm': sic_ipsl, 'miroc': sic_miroc,\n",
    "             'mpi': sic_mpi, 'hadisst': sic_hadisst, 'nsidc': sic_nsidc}\n",
    "mod_to_plot = ['ecearth', 'norcpm1_1', 'norcpm1_2', 'canesm', 'ipsl-cm', 'miroc', 'mpi', 'hadisst', 'nsidc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARCTIC # (Plot Models and Observations)\n",
    "#~~~~~~~~#\n",
    "# fig1 = plt.figure(figsize=(20,20))\n",
    "fig1, axes = plt.subplots(figsize=(20,20), constrained_layout=False) #, sharex=True, sharey=True)\n",
    "\n",
    "i = 1\n",
    "index = 0\n",
    "for m in mod_to_plot:\n",
    "    index += 1\n",
    "    axes.set_axis_off()\n",
    "\n",
    "    # Select VAR and\n",
    "    # Deal with diferent names for latitude and longitude coordinates\n",
    "    if m == 'hadisst':\n",
    "        sic_model = dic_mod[m]['sic']*100\n",
    "        latitude = sic_model.latitude\n",
    "        longitude = sic_model.longitude\n",
    "        first_month = sic_model\n",
    "    else:\n",
    "        sic_model = dic_mod[m]['siconc']\n",
    "        if m == 'nsidc':\n",
    "            first_month = sic_model\n",
    "            latitude = sic_model.latitude\n",
    "            longitude = sic_model.longitude\n",
    "        else:\n",
    "            first_month = sic_model.sel(time='1962-11-16')\n",
    "            if np.str(dic_mod[m].source_id) == 'IPSL-CM6A-LR':\n",
    "                latitude = sic_model.nav_lat\n",
    "                longitude = sic_model.nav_lon\n",
    "            else:\n",
    "                latitude = sic_model.latitude\n",
    "                longitude = sic_model.longitude\n",
    "    \n",
    "    # New evenly spaced, monotonically increasing lat-lon grid for regridding the sea ice\n",
    "    # concentration for the contour plot (otherwise the contour will reverse on itself)\n",
    "    res_new = 1 # degrees; the resolution of the new grid\n",
    "    lat_new = -90 + np.arange((2*90)/res_new) # 1+(2*90)\n",
    "\n",
    "    lon_new = np.arange((360)/res_new) # 1 +(360\n",
    "    lon_new, lat_new = np.meshgrid(lon_new,lat_new)\n",
    "\n",
    "    ice_edge_conc = 15 # the concentration threshold for the sea ice edge\n",
    "\n",
    "    # Load in the sea ice concentration for the months I want,\n",
    "    # average it over those months, and find its size\n",
    "    \n",
    "    data = np.squeeze(np.array(first_month))\n",
    "    ndim0 = np.size(data,axis=0)\n",
    "    ndim1 = np.size(data,axis=1)\n",
    "    \n",
    "    if m is not 'hadisst':\n",
    "        # Regrid\n",
    "        data_new = data\n",
    "        lat_temp = latitude.copy()\n",
    "        lon_temp = longitude.copy()\n",
    "        method = np.str('bilinear')\n",
    "        method = np.str('nearest_s2d')\n",
    "\n",
    "        # Make sure the dimensions of the new grid are in the right order\n",
    "        lat_temp = lat_new.copy()\n",
    "        lon_temp = lon_new.copy()\n",
    "        if ndim0>ndim1:\n",
    "            lat_temp = np.transpose(lat_temp)\n",
    "            lon_temp = np.transpose(lon_temp)\n",
    "\n",
    "        lat_temp2 = latitude.copy()\n",
    "        lon_temp2 = longitude.copy()\n",
    "        # lat_temp2[np.abs(lat_temp2)>90] = np.nan\n",
    "        # lon_temp2[np.abs(lon_temp2)>360] = np.nan #-- > ERROR because it is not a list\n",
    "\n",
    "        # Create the xarray datasets to feed into the xesmf regridder\n",
    "        ds_in = xr.Dataset({'lat': (['x','y'],lat_temp2),\n",
    "                            'lon': (['x','y'],lon_temp2)})\n",
    "        ds_out = xr.Dataset({'lat': (['x','y'],lat_temp),\n",
    "                                'lon': (['x','y'],lon_temp)})\n",
    "        # Regrid the data\n",
    "        f = xe.Regridder(ds_in, ds_out, method, periodic=True, reuse_weights=True)\n",
    "        data_new = f(data)\n",
    "\n",
    "        # A data mask for NortPolarStereo plots\n",
    "        mydata = ma.masked_where(latitude<0.,data.copy())\n",
    "        mydata_new = ma.masked_where(lat_temp<0.,data_new.copy())\n",
    "    elif m == 'hadisst':\n",
    "        lon_temp = longitude\n",
    "        lat_temp = latitude\n",
    "        mydata = data.copy()\n",
    "        mydata_new = data.copy()\n",
    "        \n",
    "    # Compute a circle in axes coordinates, which we can use as a boundary\n",
    "    # for the map. We can pan/zoom as much as we like - the boundary will be\n",
    "    # permanently circular.\n",
    "    theta = np.linspace(0, 2*np.pi, 100)\n",
    "    center, radius = [0.5, 0.5], 0.5\n",
    "    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "    circle = mpath.Path(verts * radius + center)\n",
    "    # Make a pcolor plot of sea ice concentration, and contour the sea ice edge\n",
    "    ax = fig1.add_subplot(5, 4, index, projection = ccrs.NorthPolarStereo()) # 5, 4\n",
    "    ax.add_feature(cfeature.LAND,zorder=100,edgecolor='black',facecolor='Grey')\n",
    "    ax.set_boundary(circle, transform=ax.transAxes)\n",
    "    ax.set_extent([-180, 180, 55, 90], crs=ccrs.PlateCarree())\n",
    "    # ax.set_extent([0.005, 360, -90, -50], crs=ccrs.PlateCarree()) # South Pole\n",
    "    this = ax.pcolormesh(longitude,latitude,mydata,transform=ccrs.PlateCarree(),cmap = plt.cm.Blues_r, vmin=0, vmax=100)\n",
    "    this2 = ax.contour(lon_temp,lat_temp,mydata_new,[ice_edge_conc],transform=ccrs.PlateCarree(),colors='orange')\n",
    "    if m == 'nsidc':\n",
    "        plt.title('NSIDC')\n",
    "    elif m == 'hadisst':\n",
    "        plt.title('HadiSST')\n",
    "    else:\n",
    "        plt.title(np.str(dic_mod[m].source_id))\n",
    "    \n",
    "fig1.colorbar(this, ax=axes, orientation='horizontal', fraction = 0.09, label = 'Sea Ice Concentration (%)')#, shrink=-0.6)\n",
    "# plt.show()\n",
    "# plt.savefig('example.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
